---
title: "오픈채팅방 데이터 탐색"
auther: "최의용"

output:
  html_document:
    fig_width: 10
    fig_height: 6
    highlight: textmate
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_height: 6
    fig_width: 10
    toc: no
  word_document:
    fig_height: 6
    fig_width: 9
    toc: no    
---

<br><br>
데이터 분석 분야의 오픈채팅방이 얼마나 활발하게 진행 되고 있는지 파악해보자. 중점은 비정형 데이터인 카카오톡 데이터를 정형화 시키느것, 반응형 그래프와 테이블을 만들었다는것, 그리고 도메인 지식이 없으면 이에 대한 해석이 힘들 거라느 점이다.
이곳에서 코드 설명은 따로 하지 않을 예정이고, 코드 설명에 대한 내용은 블로그에다가 나누어서 설명을 해보려고 한다.

### **문의** <br>
이름: 최의용 <br>
Email : shjj08@gmail.com <br>
블로그 주소: [오픈채팅방 분석 - 비정형 데이터의 정형화](https://medium.com/@unfinishedgod/%EC%98%A4%ED%94%88%EC%B1%84%ED%8C%85%EB%B0%A9-%EB%B6%84%EC%84%9D-1-%EB%B9%84%EC%A0%95%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EC%A0%95%ED%98%95%ED%99%94-c6dc537d4846) <br>
깃허브 주소: [https://github.com/Unfinishedgod/katalk_textmining](https://github.com/Unfinishedgod/katalk_textmining)  <br>
페이스북 주소: [https://www.facebook.com/shjj08](https://www.facebook.com/shjj08) <br>

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r results='hide', message=FALSE, warning=FALSE, echo=FALSE,include = FALSE}
library(dplyr)
library(lubridate)
library(stringr)
library(ggplot2)
library(rmarkdown)

library(DT)
library(kableExtra)
library(extrafont)
library(plotly)

# 워드 클라우드 Library
library(wordcloud)
library(RColorBrewer)
library(KoNLP)
```

![](https://scontent-icn1-1.xx.fbcdn.net/v/t1.0-9/48384640_2363919153678448_3037507189351645184_o.jpg?_nc_cat=107&_nc_oc=AQlL65pC1dtFZP4uOxxUmzMR3yZPJASB7qPI93-UWi22lJabrYx8dunHOeRhNK6_UkU&_nc_ht=scontent-icn1-1.xx&oh=e813ea836c7e880e5387f709a3be67f9&oe=5DD5702A)

## **캐글 코리아** <br><br>
**캐글 코리아는 이런 공유 정신에 입각하여, 데이터 사이언스, 머신 러닝, 딥러닝을 공부하고자 하는 분들이 캐글에서 쉽게 공부하실 수 있도록 함께 돕도록 만들어진 커뮤니티 입니다.** 라고 소개를 하는 커뮤니티이다. <br>
현재 약 1035명(2019-08-07기준) 정도가 오픈채팅방에 소속되어 있다. <br>
그럼 이제 이 곳의 7월 오픈채팅방의 생태계를 조사해보자. <br>

공식 링크: [https://www.facebook.com/groups/KaggleKoreaOpenGroup/](https://www.facebook.com/groups/KaggleKoreaOpenGroup/) <br>
카톡 링크: https://open.kakao.com/o/gP24T89 <br>

```{r echo=FALSE}
# args=(commandArgs(TRUE))
# txt_name <- args
txt_name <- "kaggle_talk"


dir <- paste0(getwd(),"/Textfile/")


text_file <- paste0(txt_name,".txt")

text_value <- paste0(dir,text_file)

kko <- readLines(text_value)

raw_df <- kko

## Test용

# 월, 일, 오전, 오후 기준 설정
# 21, 22번째 글자 까지 하드 코딩
index_date <- grepl(",",str_sub(raw_df,21,22)) & 
  grepl("월",raw_df) & 
  grepl("일",raw_df) &
  (grepl("오전",raw_df) |
     grepl("오후",raw_df))

# raw 재 설정
raw_df_2 <- raw_df[index_date]

# 첫번째 comma 찾기
comma_pattern <- regexpr(",",raw_df_2)

# comma 별 글자 선택
kko_date <- str_sub(raw_df_2,1,comma_pattern-1)

# 문자열 최대 길이 
nchar_max <- max(nchar(raw_df_2))

# 각 comma 기준 뒤에 나오는 text 선정 
kko_text <- str_sub(raw_df_2,comma_pattern + 2,nchar_max)

## Username이 나오는 경우
# colon 나오는 텍스트만 추출
text_colon_index <- grep(":",kko_text)

kko_text_colon <- kko_text[text_colon_index]

# colon
colon_grep <- regexpr(":",kko_text_colon)

# Username, text 별 DF 생성
text_only_df <- cbind(
  text_colon_index,
  str_sub(kko_text_colon,1,colon_grep-2),
  str_sub(kko_text_colon,colon_grep + 2,nchar_max)
) 

## Username이 나오지 않는 경우
# colon이 나오지 않는 텍스트 선정
text_notcolon_index <- which(!grepl(":",kko_text))


# colon나오지 않는 패턴
text_pattern <- c("님이 들어왔습니다.",
                  "님이 나갔습니다.",
                  "채팅방 관리자가 메시지를 가렸습니다.",
                  "님을 내보냈습니다.",
                  "삭제된 메시지입니다.",
                  "변경되었습니다.")

# 각 패턴별 df 생성
pattern_df <- c()
# pattern_msg <- text_pattern[1]
for(pattern_msg in text_pattern) {
  pattern_index <- grep(pattern_msg,kko_text)
  # pattern_index <- which(pattern_msg == kko_text)
  pattern_index <- intersect(text_notcolon_index,pattern_index)
  
  pattern_grep <- regexpr(pattern_msg,kko_text[pattern_index])
  
  pattern_raw_df <- cbind(
    pattern_index,
    str_sub(kko_text[pattern_index],1,pattern_grep-1),
    str_sub(kko_text[pattern_index],pattern_grep,nchar_max)
  )
  pattern_df <- rbind(pattern_df,pattern_raw_df)
}

# username이 있는 경우 없는 경우 합치기
total_df <- as.data.frame(
  rbind(
    text_only_df,
    pattern_df 
  )
)


total_df[,1] <- as.numeric(as.character(total_df[,1]))
total_df[,2:3] <- sapply(total_df[,2:3], as.character)
# total_df[,3] <- as.character(total_df[,3])

total_df <- total_df %>% arrange(text_colon_index)

total_df <- cbind(kko_date,total_df[,2:3])

# 날짜형 변환
total_df[,1] <- gsub(",","",total_df[,1])
total_df[,1] <- gsub("년 ","-",total_df[,1])
total_df[,1] <- gsub("월 ","-",total_df[,1])
total_df[,1] <- gsub("일 "," ",total_df[,1])
total_df[,1] <- gsub("오전 ","",total_df[,1])

pm_index <- grep("오후",total_df[,1])
total_df[,1] <- gsub("오후 ","",total_df[,1])



total_df[,1] <- as.POSIXct(total_df[,1])

total_df[pm_index,1] <- total_df[pm_index,1] + 60*60*12
# hour(total_df[pm_index,1]) <- hour(total_df[pm_index,1]) + 12

rownames(total_df) <- NULL
colnames(total_df) <- c("Date","User","Message")
total_df$User[grep("회원님",total_df$User)] <- "의용"


head_null_index <- grep(" ",str_sub(total_df$User,1,1))

total_df$User[head_null_index] <- gsub(" ","",total_df$User[head_null_index])

# User로 변경
total_df$User <- factor(total_df$User)
levels(total_df$User) <- paste0("User",c(1:length(levels(total_df$User))))
```


```{r echo=FALSE}
# 카톡 공식 메시지 제거 하고 하기.
pattern_test <- FALSE
for(pattern in text_pattern) {
  pattern_test <- pattern_test | grepl(pattern, total_df$Message)
}


talk_ratio_df <- total_df[!pattern_test,]


month_set <- 7
# useSejongDic()
month_range <- paste0("2019-0",month_set,"-01")
month_range_next <- paste0("2019-0",month_set+1,"-01")

month_setting <- talk_ratio_df$Date >= month_range &
  talk_ratio_df$Date < month_range_next

talk_ratio_df <- talk_ratio_df[month_setting,]
```


```{r echo=FALSE}
talk_ratio_time_df <- talk_ratio_df %>%
  mutate(day = ymd(str_sub(talk_ratio_df[,1],1,10))) %>%
  mutate(wday = wday(str_sub(talk_ratio_df[,1],1,10), TRUE)) %>%
  mutate(hour = ymd_h(str_sub(talk_ratio_df[,1],1,13))) %>%
  mutate(minute = ymd_hm(str_sub(talk_ratio_df[,1],1,16))) %>%
  mutate(count = rep(1,nrow(talk_ratio_df)))
```

<br>

### **1. 일별 카톡 트래픽**
하루에 몇개의 카톡이 오고 가는가를 보려고 한다. 경험상 1200명의 사람들이 매일 같이 질문답변을 함에도, 많이 하는날이 있고 적게 하는 날이 있었다.

<br>

```{r echo=FALSE}
group_by_day_df <- talk_ratio_time_df %>%
  group_by(day) %>%
  summarise(count = sum(count)) %>%
  # arrange(desc(count)) %>%
  as.data.frame()

# plot(group_by_day_df, lty="l")

group_by_day_plot <- ggplot(group_by_day_df, aes(x=day, y=count, colours=day)) +
  geom_point(stat = "identity") +
  # geom_bar(stat = "identity") + 
  geom_line(stat = "identity") + 
  # scale_x_continuous(breaks=seq("2019-07-01","2019-07-31", "1")) + 
  theme(axis.text.x = element_text(angle = 30))
  # theme(axis.title.x=element_blank(),
  #       axis.text.x=element_blank(),
  #       axis.ticks.x=element_blank())

ggplotly(group_by_day_plot, height = 500, width=700)

```
<br>

### **2. 시간별 카톡 트래픽**
시간별 얼마나 카톡이 오고가는지 알아보자. 이 수치를 알아보는 이유는 다음과 같다. <br>
 - 주로 몰리는 특정 시간대가 있는가? <br>
 - 또는, 주로 몰리게 되는 주요 **키워드**가 존재하는가? <br>
몰리는 시간대야 쉽게 이를 통해 알 수 있지만 이 카톡방에서의 경험상 특히 몰리는 키워드가 있었다.(Ex. 모각캐 가시는분 계신가요?, 이러이러한 공부중인데 추천해주실만한 캐글 대회가 있나요? 등등)


<br>
```{r echo=FALSE}
group_by_hour_df <- talk_ratio_time_df %>%
  group_by(hour) %>%
  summarise(count = sum(count)) %>%
  as.data.frame()

group_by_hour_plot <- ggplot(group_by_hour_df, aes(x=hour, y=count, colours=hour)) +
  geom_line(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 30))


ggplotly(group_by_hour_plot, height = 550, width=700)
```

<br>

### **3. 자주 쓰는 단어**
시간대별 트래픽이중 상위 4개의 시간에 대한 키워드를 알아보자. 트래픽이 몰렸을때의 주요 키워드를 알아보도록 하자. 가령, 시간대가 점심이면 점심밥에 대한 이야기를, 금요일 밤이면, 월요일 아침이면, 그에 대한 키워드가 나올 것이다. 그리고 특정 키워드가 사람들을 참여하게 한다면 어떤 키워드 인지도 파악해보자.

<br>

```{r echo=FALSE}
group_by_hour_df_arrange <- group_by_hour_df %>% 
  arrange(desc(count))

total_word.freq_time_df <- data.frame()
for(i in 1:5) {
talk_densetopn_msg <- talk_ratio_time_df[talk_ratio_time_df$hour %in% group_by_hour_df_arrange$hour[i],]$Message


word_test_df <- talk_densetopn_msg

# "" 제거
word_test_df <- word_test_df[which(word_test_df != "")]

# 특수문자 제거
word_test_df <- str_replace_all(word_test_df, "\\W", " ")


nouns <- KoNLP::extractNoun(word_test_df)

# table 형태로 변환
wordcount <- table(unlist(nouns))

df.word  <- as.data.frame(wordcount, stringsAsFactors = FALSE)

df.word <- rename(df.word, word = Var1, freq = Freq)


word.freq  <- df.word %>% filter(nchar(word) >=2) %>% arrange(desc(freq)) 

# %>% arrange(desc(freq))

lol_list <- 
grepl("ㅎ",word.freq[,1]) |
  grepl("ㅋ",word.freq[,1]) | 
  grepl("ㄷ",word.freq[,1]) |
  grepl("이모",word.freq[,1]) 

word.freq <- word.freq[!lol_list,]


word.freq_time_df <- cbind(word.freq[1:20,],"time" = rep(group_by_hour_df_arrange[i,1],20))
total_word.freq_time_df <- rbind(total_word.freq_time_df,word.freq_time_df)
}

total_word.freq_time_df <- total_word.freq_time_df %>% 
  filter(!(word %in% c("유한","성윤","세원",total_word.freq_time_df[15,1])))
```

#### **`r group_by_hour_df_arrange[1,1]` ~  `r group_by_hour_df_arrange[1,1] + 60*59` ** 의 키워드<br>
1시간동안 `r group_by_hour_df_arrange[1,2]`건의 카톡을 했다. 아래 그래프를 보자. 캐글 채팅방 답게, 가장 많은 단어는 AI, 커널이다, 동시에 캐글,참여,csv,kernel 답변 등등이 보인다. 이방에서 캐글과 공부 방법에 대한 이야기가 주로 나오긴 했었다.

```{r echo=FALSE}
total_word.freq_time_df %>% 
  filter(time == unique(total_word.freq_time_df$time)[1]) %>% 
  datatable()
```

#### **`r group_by_hour_df_arrange[2,1]` ~  `r group_by_hour_df_arrange[2,1] + 60*59` ** 의 키워드<br>
1시간동안 `r group_by_hour_df_arrange[2,2]`건의 카톡을 했다. 아래 그래프를 보자. 정리,기억, 공부, 블로그, 마크, 다운등의 키워드가 보인다. "공부한거 정리 어떻게 하세요 기억이 안나는요?" 정도의 질문부터 시작해서 "블로그에 정리해요 저는", "마크다운으로 정리 하세요" 등등의 대화가 오갔을 것이다.

```{r echo=FALSE}
total_word.freq_time_df %>% 
  filter(time == unique(total_word.freq_time_df$time)[2]) %>% 
  datatable()
```

#### **`r group_by_hour_df_arrange[3,1]` ~  `r group_by_hour_df_arrange[3,1] + 60*59` ** 의 키워드<br>
1시간동안 `r group_by_hour_df_arrange[3,2]`건의 카톡을 했다. 아래 그래프를 보자. 커널이야 자주 사용되는 단어니까 패스. 그러나 notebook과 colab라는 단어가 눈에 띈다. 이 단어는 주로 파이썬 사용시 notebook을 사용하는지 google colab을 사용하는지에 대한 이야기다.
 
```{r echo=FALSE}
total_word.freq_time_df %>% 
  filter(time == unique(total_word.freq_time_df$time)[3]) %>% 
  datatable()
```

#### **`r group_by_hour_df_arrange[4,1]` ~  `r group_by_hour_df_arrange[4,1] + 60*59` ** 의 키워드<br>
1시간동안 `r group_by_hour_df_arrange[4,2]`건의 카톡을 했다. 아래 그래프를 보자. 모각캐... 이 모.각.캐라는 단어는 **모여서 각자 캐글**의 준말로, 모.각.코(**모여서 각자 코딩**)을 어원?으로 하고 있다. 2019년 모각캐의 일정은 08.10일로 7월 22일 즈음 부터 현 시점(8월 7일)까지도 꾸준하게 나오는 단어이다. 추가로, 토치는, 파이토치, keras, pytorch 라는 단어가 보이는데 이 단어들은 모두 딥러닝 라이브러리를 뜻한다.

```{r echo=FALSE}
total_word.freq_time_df %>% 
  filter(time == unique(total_word.freq_time_df$time)[4]) %>% 
  datatable()
```


<br>

### **4. 파레토 법칙**
파레토 법칙이 어떻게 적용 되는가?<br>
- 파레토 법칙: 파레토 법칙( - 法則, 영어: Pareto principle, law of the vital few, principle of factor sparsity) 또는 80 대 20 법칙(영어: 80–20 rule)은 '전체 결과의 80%가 전체 원인의 20%에서 일어나는 현상'을 가리킨다.[3] 예를 들어, 20%의 고객이 백화점 전체 매출의 80%에 해당하는 만큼 쇼핑하는 현상을 설명할 때 이 용어를 사용한다. 2 대 8 법칙라고도 한다. (출처: 위키) <br>

말 그대로 오픈채팅방에서 전체 카톡의 80%를 차지하는 대화가 주 멤버 20%의 비율에서 나오는지 알아보려고 한다. 한계점이 있다면, 카톡에서는 대화를 할때 문장을 작성하는 경우도 있지만 단어를 한줄씩 작성하면서 문장을 완성하는 경우도 있다. <br>
아래 테이블로 대화의 비중에서 80% 에 해당하는 비율이 몇%를 차지하는지 알아보자. <br>
보면 단 6명의 대화가 전체 대화의 20%를 차지 하는데, 이를 해석 해보자면
- 카톡 대화 전처리의 한계
- 잠수중인 인원 처리의 한계
- 극심한 양극화 (커뮤니티의 특성상 이 현상은 종종 보이긴 하더라.)
정도로 해석해 볼 수 있겠다.

```{r echo=FALSE}
## 참여율 높은 회원
group_by_talk_df <- talk_ratio_time_df %>%
  group_by(User) %>%
  summarise(count = sum(count)) %>%
  arrange(desc(count)) %>%
  as.data.frame()

# 전체 대화에서의 비율 조사
group_by_talk_df <- group_by_talk_df %>% 
  mutate(ratio = round(prop.table(group_by_talk_df[,2])  * 100,5)) %>% # 비율  prop.table 함수
  mutate(cum_ratio = cumsum(ratio)) # 누적 비율 cumsum 함수
```


```{r echo=FALSE}
datatable(group_by_talk_df)
```

<br>

### **5. 7월의 가입/탈퇴**
7월 한달 동안 몇명이 가입 했고, 몇명이 나갔고, 이 트렌드는 어떠 할까? <br>

```{r echo=FALSE}
join_out_tf <- FALSE

for(pattern in text_pattern[1:2]) {
  join_out_tf <- join_out_tf | (pattern == total_df$Message)
  
}

out_df <- total_df[join_out_tf,]

# 이중 7월달만 사용
month_setting <- out_df$Date >= month_range &
  out_df$Date < month_range_next

out_df <- out_df[month_setting,]


out_df_clean <- out_df %>%
  mutate(day = ymd(str_sub(out_df[,1],1,10))) %>%
  mutate(wday = wday(str_sub(out_df[,1],1,10), TRUE)) %>%
  mutate(hour = ymd_h(str_sub(out_df[,1],1,13))) %>%
  mutate(minute = ymd_hm(str_sub(out_df[,1],1,16))) %>%
  mutate(count = rep(1,nrow(out_df)))

# unique(out_df_clean_group$Message)

join_out_sum <- out_df_clean %>% 
  group_by(Message) %>% 
  summarise(count = sum(count)) %>%
  as.data.frame()

out_df_clean_group <- out_df_clean %>%
  group_by(day, wday, Message) %>%
  summarise(count = sum(count)) %>%
  as.data.frame()

plot_p <- ggplot(out_df_clean_group, aes(x=day, y=count, group = Message, colour = Message)) +
  geom_line(size=1) +
  theme(legend.position = "top") 
```

총 `r join_out_sum[1,2]` 명이 나갔고, `r join_out_sum[2,2]`명이 들어 왔다. 매우 재밌는 그래프다. 가입률이 낮은 수준에 머물러 있다가 특정 하루에 급격하게 성장한 이후로 많은 가입률을 보이고 있다. 7월 17일에 139명이나 가입을 했다. 이 원인은 페이스북에서 찾을수 있는데 캐글코리아 페이스북 관리자분이 오픈채팅방 링크와 함께 캐글 홍보를 올렸다. 그래서 페이스묵 링크를 타고 많은 사람들이 오픈채팅방의 존재를 알게 되고 들어 왔다.

![](/home/owen/katalk_textmining/kaggle_admin_link.PNG)

```{r echo=FALSE}
ggplotly(plot_p, height = 500, width=800)
```
<br>

---

<br>

## **총평** <br><br>

내가 주로 사용하는 오픈채팅방의 비정형 데이터를 정형화 시켜서, 그리고 나의 경험에 비추어서 분석을 해보았다. 특히 캐글 오픈채팅방의 경우에는 캐글,커널,모각캐 라는 단어가 자주 보일 정도로 도메인 지식이 없이는 해석이 힘들것이라 판단 된다. 그리고, 시간별 트렌드에서 단어 선정을 하도록 하는것보다는 일별로 또는 특정 이벤트를 파악하고 진행 하는 것도 필요해 보인다.
